{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport torch\nfrom torchvision import datasets,transforms,io\nfrom torch import utils\nfrom collections import Counter","metadata":{"id":"acc208d6","execution":{"iopub.status.busy":"2022-10-21T01:05:43.394451Z","iopub.execute_input":"2022-10-21T01:05:43.394898Z","iopub.status.idle":"2022-10-21T01:05:43.401295Z","shell.execute_reply.started":"2022-10-21T01:05:43.394862Z","shell.execute_reply":"2022-10-21T01:05:43.400402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"id":"vp8WzUuBwMy6","outputId":"f61167b2-51c6-4244-8302-f65c9767ae2c","execution":{"iopub.status.busy":"2022-10-21T01:05:43.406981Z","iopub.execute_input":"2022-10-21T01:05:43.407341Z","iopub.status.idle":"2022-10-21T01:05:43.413792Z","shell.execute_reply.started":"2022-10-21T01:05:43.407313Z","shell.execute_reply":"2022-10-21T01:05:43.412730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Loading Images:**\n\nFirst step of any Neural Network/Machine Learning problem is the loading the input data. Here in this cell we will load the given input images. The problem set gives us different types of images of Bikes, Airplanes, Schooners. And we have to create a neural network model that will classify a given image in to these three categories. \nHere given images are in different shapes so while loading these images we will transform them into 512x512 pixels size and then convert them into Tensors.\nTensor is a numpy array like data structure which is developed for handling arrays of large size for example image arrays.\n\nNext, we will split our input dataset into three sub datasets i.e. training dataset, validation dataset and testing dataset. Here we have kept around 20% of total data aside for testing and remaining 80% data we will use for traning and validation.\n\nWe will convert these three datasets into respective dataloader object. Dataloader object will be used for iterating over the these data and divide them in batches.\n","metadata":{"id":"rQOYtQztZshA"}},{"cell_type":"code","source":"# for i,data in enumerate(trainDataLoader):\n#     print(len(data[0]))","metadata":{"execution":{"iopub.status.busy":"2022-10-21T01:05:43.419577Z","iopub.execute_input":"2022-10-21T01:05:43.419864Z","iopub.status.idle":"2022-10-21T01:05:43.426320Z","shell.execute_reply.started":"2022-10-21T01:05:43.419840Z","shell.execute_reply":"2022-10-21T01:05:43.425410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([transforms.Resize((512,512)),transforms.ToTensor()])\ndataset = datasets.ImageFolder('../input/caltech101-airplanes-motorbikes-schooners/caltech101_classification/',transform=transform)\ntrainData,validationData,testData = utils.data.random_split(dataset,[930,400,331],generator=torch.Generator().manual_seed(42))\nplt.imshow(trainData[230][0].permute(1,2,0))\ntrainDataLoader = torch.utils.data.DataLoader(trainData, batch_size=32, shuffle=True)\nvalidationDataLoder = torch.utils.data.DataLoader(validationData, batch_size=32, shuffle=True)\ntestDataLoader = torch.utils.data.DataLoader(testData, batch_size=32, shuffle=True)\nlen(validationDataLoder.dataset)","metadata":{"id":"d8eb6c21","outputId":"6a4d0564-da3f-4b6a-9dd4-2fe6f9fc87e9","execution":{"iopub.status.busy":"2022-10-21T01:05:43.433209Z","iopub.execute_input":"2022-10-21T01:05:43.433469Z","iopub.status.idle":"2022-10-21T01:05:43.722670Z","shell.execute_reply.started":"2022-10-21T01:05:43.433446Z","shell.execute_reply":"2022-10-21T01:05:43.721727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# validationDataLoder","metadata":{"id":"9BzsN7IpljD2","outputId":"5cb206cb-4661-4222-b26f-7edcaa176e7d","execution":{"iopub.status.busy":"2022-10-21T01:05:43.724502Z","iopub.execute_input":"2022-10-21T01:05:43.725305Z","iopub.status.idle":"2022-10-21T01:05:43.730503Z","shell.execute_reply.started":"2022-10-21T01:05:43.725260Z","shell.execute_reply":"2022-10-21T01:05:43.729321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNN2(torch.nn.Module):\n#     __name__=\"Model2\"\n    def __init__(self):\n        super(CNN2, self).__init__()\n        ###############################\n        # Original Input image: (224,224,3)\n        # Conv : (224,224,16)\n        # Pool: (112,112,16)\n        self.layer1 = torch.nn.Sequential(\n            torch.nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n        ########################################\n        # Input Image: (112,112,16)\n        # Conv: (112,112,64)\n        # Pool: (56,56,64)\n        self.layer2 = torch.nn.Sequential(\n            torch.nn.Conv2d(16, 64, kernel_size=3, stride=1, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n        ############################################\n        # FC 28*28*128 -> 625\n        self.fc1 = torch.nn.Linear(128*128 * 64, 3, bias=True) # size of image input to this layer * 128\n        torch.nn.init.xavier_uniform_(self.fc1.weight)\n        self.layer4 = torch.nn.Sequential(\n            self.fc1,\n            torch.nn.ReLU()\n        )\n\n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = out.view(out.size(0), -1)   # Flatten them for FC\n        out = self.fc1(out)\n        return out\n\n\n#instantiate CNN model\nmodel2 = CNN2()\nmodel2\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel2.to(device)","metadata":{"id":"74258a61","execution":{"iopub.status.busy":"2022-10-21T01:05:43.732414Z","iopub.execute_input":"2022-10-21T01:05:43.732852Z","iopub.status.idle":"2022-10-21T01:05:43.799196Z","shell.execute_reply.started":"2022-10-21T01:05:43.732817Z","shell.execute_reply":"2022-10-21T01:05:43.798186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNN3(torch.nn.Module):\n    __name__=\"Model3\"\n    def __init__(self):\n        super(CNN3, self).__init__()\n        ###############################\n        # Original Input image: (512,512,3)\n        # Conv : (512,512,16)\n        # Pool: (256,256,16)\n        self.layer1 = torch.nn.Sequential(\n            torch.nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n        ########################################\n        # Input Image: (256,256,16)\n        # Conv: (256,256,64)\n        # Pool: (128,128,64)\n        self.layer2 = torch.nn.Sequential(\n            torch.nn.Conv2d(16, 64, kernel_size=3, stride=1, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n        ###############################\n        # Input image: (128,128,64)\n        # Conv : (128,128,128)\n        # Pool: (64,64,128)\n        self.layer3 = torch.nn.Sequential(\n            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n        ############################################\n        # FC 28*28*128 -> 625\n        self.fc1 = torch.nn.Linear(64*64 * 128, 256, bias=True) # size of image input to this layer * 128\n        torch.nn.init.xavier_uniform_(self.fc1.weight)\n        self.layer4 = torch.nn.Sequential(\n            self.fc1,\n            torch.nn.ReLU()\n        )\n        ############################################\n        # FC 256 -> 3 Classes\n        self.fc2 = torch.nn.Linear(256, 3, bias=True) # size of image input to this layer * 128\n        torch.nn.init.xavier_uniform_(self.fc2.weight)\n        self.layer5 = torch.nn.Sequential(\n            self.fc2,\n            torch.nn.ReLU()\n        )\n\n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = out.view(out.size(0), -1)   # Flatten them for FC\n        out = self.fc1(out)\n        out = self.fc2(out)\n        return out\n\n\n#instantiate CNN model\nmodel3 = CNN3()\nmodel3\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel3.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-10-21T01:05:43.802161Z","iopub.execute_input":"2022-10-21T01:05:43.802530Z","iopub.status.idle":"2022-10-21T01:05:46.199829Z","shell.execute_reply.started":"2022-10-21T01:05:43.802494Z","shell.execute_reply":"2022-10-21T01:05:46.198816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Creating CNN Architectures:**\n\nIn this code block we have defined the architecture of our Convolutional Networks. We have created 3 convolutional layers and 2 fully connected layers.\nEach convolutional layer will have a pooling layer attached after it. This block of code is the essence of our CNN. Brief information about these layers is as mentioned below.</br>\n**Conv Layer:**  In this layer number of kernels of size specified by user will be used to convolve on the given input image matrix. Kernel is basically a small matrix which will be used to learn some specific feature in the image. For example, one kernel can be used to determine the vertical line in the image, another kernal can used to determine a curve in the image.</br>So during training phase of the model, these kernal are learned and used later in testing phase to determine that feature in the test image.</br>\nHere the first layer, we have used a 16 kernels of size 3, stride=1 and padding=1. which will have the original image as an input and will output activation maps of dimensions 512x512x16.\n</br>**ReLU:**\nReLU is the activation function. It will apply an elementwise activation function, such as the max(0,x) thresholding at zero. This leaves the size of the volume unchanged ([512x512x16]).[1]\n</br>**Pooling Layer:** As the size of the channels increases the weights associated with them also increases which leads to performance degredation. So, to solve this problem pooling layer is used. Pooling layer is used to reduce the size of input image. It will use a pooling technique to reduce the size image. Max pooling is the type of pooling which will convolve an nxn kernel on the image and will select the maximum element from the window.\nIt will output an image of dimensions\n<br>W2=(W1−F)/S+1\n<br>H2=(H1−F)/S+1\n<br>D2=D1<br>\nwhere W2, H2 are the dimensions of the output image and W1,H1 are the dimensions of input image and F is size of the pooling kernel and S is the stride.\n</br><br>\nIn CNN multiple conv layer and pool layers will be chained together, so output of the previous layer will be the input of next layer.\n<br><br>\n***Fully connected Layer:***<br>\nThe fully-connected layer is called the “output layer” and in classification settings it represents the class scores.[1]<br>\nThe last fully connected layer will have output channesl numers equal to the number of classes in problem. For this classification problem we have three classes (Motorbike, Ariplane, Schooner) so our fully connected layer will have 3 as output channel and will output the volumn of [1x1x3].<br> ","metadata":{"id":"Wjp6L7XGdkBA"}},{"cell_type":"code","source":"class CNN4(torch.nn.Module):\n    __name__=\"Model4\"\n    def __init__(self):\n        super(CNN4, self).__init__()\n        ###############################\n        # Original Input image: (512,512,3)\n        # Conv : (512,512,16)\n        # Pool: (256,256,16)\n        self.layer1 = torch.nn.Sequential(\n            torch.nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n        ########################################\n        # Input Image: (256,256,16)\n        # Conv: (256,256,64)\n        # Pool: (128,128,64)\n        self.layer2 = torch.nn.Sequential(\n            torch.nn.Conv2d(16, 64, kernel_size=3, stride=1, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n        ###############################\n        # Input image: (128,128,64)\n        # Conv : (128,128,128)\n        # Pool: (64,64,128)\n        self.layer3 = torch.nn.Sequential(\n            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n        ###############################\n        # Input image: (64,64,128)\n        # Conv : (64,64,512)\n        # Pool: (32,32,512)\n        self.layer4 = torch.nn.Sequential(\n            torch.nn.Conv2d(128, 512, kernel_size=3, stride=1, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n        ############################################\n        # FC 28*28*128 -> 625\n        self.fc1 = torch.nn.Linear(32*32 * 512, 256, bias=True) # size of image input to this layer * 128\n        torch.nn.init.xavier_uniform_(self.fc1.weight)\n        self.layer5 = torch.nn.Sequential(\n            self.fc1,\n            torch.nn.ReLU()\n        )\n        ############################################\n        # FC 28*28*128 -> 625\n        self.fc2 = torch.nn.Linear(256,512, bias=True) # size of image input to this layer * 128\n        torch.nn.init.xavier_uniform_(self.fc2.weight)\n        self.layer6 = torch.nn.Sequential(\n            self.fc2,\n            torch.nn.ReLU()\n        )\n        ############################################\n        # FC 256 -> 3 Classes\n        self.fc3 = torch.nn.Linear(512, 3, bias=True) # size of image input to this layer * 128\n        torch.nn.init.xavier_uniform_(self.fc3.weight)\n        self.layer7 = torch.nn.Sequential(\n            self.fc3,\n            torch.nn.ReLU()\n        )\n\n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = out.view(out.size(0), -1)   # Flatten them for FC\n        out = self.fc1(out)\n        out = self.fc2(out)\n        out = self.fc3(out)\n        return out\n\n\n#instantiate CNN model\nmodel4 = CNN4()\nmodel4\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel4.to(device)","metadata":{"id":"cveP7jL4En6W","outputId":"6025cacc-141b-4cdb-b28b-cd0a7ad4bbea","execution":{"iopub.status.busy":"2022-10-21T01:05:46.202329Z","iopub.execute_input":"2022-10-21T01:05:46.202984Z","iopub.status.idle":"2022-10-21T01:05:48.864612Z","shell.execute_reply.started":"2022-10-21T01:05:46.202947Z","shell.execute_reply":"2022-10-21T01:05:48.863694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Training CNN model:**<br>\nCross Entropy Loss:\n<br>Optimizer:\n<br>Here we will use 3 epochos. Epoch is bascially number of repetations. So here the model will be trained three times on input data. In each pass the algorithm will do a forward and backward pass and update the weights by using gradients.\n","metadata":{"id":"YlJPUJPLoepk"}},{"cell_type":"code","source":"def train_cnn_function(no_epochos,lr,model):\n    import torch.optim as optim\n\n    criterion = torch.nn.CrossEntropyLoss()\n    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n\n    no_of_epochos = no_epochos\n    for epoch in range(no_of_epochos):\n        running_loss = 0.0\n        for i,data in enumerate(trainDataLoader):\n#           if(i%10==0):\n#             print(\"i=\",i)\n          inputData , lable = data[0].to(device), data[1].to(device)\n          optimizer.zero_grad()\n          output = model(inputData)\n          loss = criterion(output,lable)\n          loss.backward()\n          optimizer.step()\n          running_loss = running_loss+loss.item()\n          if i % 5 == 4:    # print every 100 mini-batches\n            print('Epoch={} Batch={} Loss= {}'.format(epoch + 1, i + 1, running_loss / 5))\n            running_loss = 0.0\n    print(\"####Finished Training######\")","metadata":{"id":"7407805f","outputId":"d38c8776-5db1-4b01-8d54-d3a76f019b57","execution":{"iopub.status.busy":"2022-10-21T01:05:48.866288Z","iopub.execute_input":"2022-10-21T01:05:48.866897Z","iopub.status.idle":"2022-10-21T01:05:48.875803Z","shell.execute_reply.started":"2022-10-21T01:05:48.866860Z","shell.execute_reply":"2022-10-21T01:05:48.874408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Testing model:**<br>\nIn this block we will test our model on validation and test dataset.\n<br>\nFirst we will move our input data to GPU and then use our CNN model to predict the class of the images. For each image we will calculate loss and correct predictions.\n<br>\nThese same steps will be used for test dataset as well.\n<br><br>\nBy using this CNN model with 3 conv layer and 2 fully connected layers we got 93% accuracy on validation dataset and **92%** accuracy on test dataset.","metadata":{"id":"APbAAB90r8IJ"}},{"cell_type":"code","source":"def test_validation_function(model):\n    valcorrect = 0\n    valtotal = 0\n    with torch.no_grad():\n        for data in validationDataLoder:\n            images, labels = data[0].to(device), data[1].to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            valtotal = valtotal + labels.size(0)\n            valcorrect = valcorrect + (predicted == labels).sum().item()\n\n    print('Accuracy of the network on validation images: %d %%' % (\n        100 * valcorrect / valtotal))\n    return(valcorrect / valtotal)\ndef test_test_function(model):\n    testcorrect = 0\n    testtotal = 0\n    with torch.no_grad():\n        for data in testDataLoader:\n            images, labels = data[0].to(device), data[1].to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            testtotal = testtotal + labels.size(0)\n            testcorrect = testcorrect + (predicted == labels).sum().item()\n\n    print('Accuracy of the network on test images: %d %%' % (\n        100 * testcorrect / testtotal))\n    return(testcorrect / testtotal)","metadata":{"id":"36499b24","outputId":"8123f6e7-5ede-4133-96a8-b451f4f35c76","execution":{"iopub.status.busy":"2022-10-21T01:05:48.877575Z","iopub.execute_input":"2022-10-21T01:05:48.878001Z","iopub.status.idle":"2022-10-21T01:05:48.890286Z","shell.execute_reply.started":"2022-10-21T01:05:48.877964Z","shell.execute_reply":"2022-10-21T01:05:48.889422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Experimentation***<br>\nIn this block of code we will manually grid search different parameters combinations.<br>\nHere we will test three different models with 2 layers, 3 layers and 4 layers.\nFor each model we have trained our cnn model with different combinations of number of epoches and learning rate. For theese different combinations, we will save their prediction accuracy on validation set and their running time.\nWe will choose the best parameters based on validation dataset accuracy and running time for training and use those parameters for test dataset.","metadata":{}},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"import itertools\nfrom datetime import datetime\n# test_accuracy=[]\nno_epo_list =[1,3,5,7]\nlr_list=[0.001,0.01]\noverallData=[]\ncombined = list(itertools.product(no_epo_list,lr_list))\nmodels={'2':model2,'3':model3,'4':model4}\nfor model in models:\n    validation_accuracy=[]\n    runningTime=[]\n    print(\"$$$$$$$$$$$$$$$$$$$$$$$$ For model with {} layers $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\n\".format(model))\n    for i in range(len(combined)):\n        print(\"Started training for parametrs: {}\".format(combined[i]))\n        start = datetime.now()\n        train_cnn_function(combined[i][0],combined[i][1],models[model])\n        end = datetime.now()\n        print(end-start)\n        totalTime=round((end - start).seconds+((end-start).microseconds /1000000),4)\n        runningTime.append(totalTime)\n        result = test_validation_function(models[model])\n        validation_accuracy.append(result)\n    #     test_accuracy.append(result[1])\n        print(\"Params: {},validation_accu:{}, time={} secs\".format(combined[i],result,totalTime))\n        print(\"______________________________________________________\")\n    # print(combined)\n    # print(validation_accuracy)\n    # print(test_accuracy)\n              ####Table print#####\n    from tabulate import tabulate\n    data=[]\n    for i in range(len(combined)):\n        data.append([str(model)+\" layers\",combined[i],validation_accuracy[i],runningTime[i]])\n    print(\"\\n\")\n    overallData.extend(data)\n    print(tabulate(data,headers=['Model Layers','Parameters(Epochs,LR)','Validation Accu','Running Time(seconds)']))\n    bestIndex=-1\n    minTime=float(\"inf\")\n    maxAccu=max(validation_accuracy)\n    for i,v in enumerate(validation_accuracy):\n        if(v==maxAccu):\n            if(runningTime[i]<minTime):\n                minTime=runningTime[i]\n                bestIndex=i\n    print(\"\\nBest Parameters: {}, Validation Acuuracy: {}, Running Time: {}\".format(combined[bestIndex],validation_accuracy[bestIndex],runningTime[bestIndex]))\n    print(\"\\nBased on these parameters, the test accuracy is:\\n\")\n    train_cnn_function(combined[bestIndex][0],combined[bestIndex][1],models[model])\n    print(test_test_function(models[model]))\n    print(\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\n\")\nprint(\"Overall Performance\\n\")\nprint(tabulate(overallData,headers=['Model Layers','Parameters(Epochs,LR)','Validation Accu','Running Time(seconds)']))","metadata":{"execution":{"iopub.status.busy":"2022-10-21T01:05:48.891656Z","iopub.execute_input":"2022-10-21T01:05:48.892241Z","iopub.status.idle":"2022-10-21T01:41:29.071924Z","shell.execute_reply.started":"2022-10-21T01:05:48.892205Z","shell.execute_reply":"2022-10-21T01:41:29.070895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**References:**<br>\n\n\n1.   [CS231n: Deep Learning for Computer Vision - Stanford - Spring 2022](https://cs231n.github.io/convolutional-networks/)\n2.   [PyTorch Tutorials](https://pytorch.org/tutorials/index.html)\n\n3.   [PyTorch Conv2D Explained with Examples](https://machinelearningknowledge.ai/pytorch-conv2d-explained-with-examples/)\n\n\n","metadata":{"id":"js5Ct1Ur0sqI"}},{"cell_type":"code","source":"# print('Actual:{} Predicted:{}'.format(testData.dataset.classes[labels[7]],testData.dataset.classes[predicted[7]]))\n# plt.imshow(images[7].cpu().permute(1,2,0))","metadata":{"id":"trYtiu2WM9Lg","outputId":"685231ef-4c9d-4145-8144-5ce4195456f5","execution":{"iopub.status.busy":"2022-10-21T01:41:29.073688Z","iopub.execute_input":"2022-10-21T01:41:29.074265Z","iopub.status.idle":"2022-10-21T01:41:29.093641Z","shell.execute_reply.started":"2022-10-21T01:41:29.074228Z","shell.execute_reply":"2022-10-21T01:41:29.091695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in testDataLoader:\n#   print('Images:{} --> Lables:{}'.format(len(i[0]),len(i[1])))","metadata":{"id":"VaOfUGtQ8dV-","execution":{"iopub.status.busy":"2022-10-21T01:41:29.095325Z","iopub.status.idle":"2022-10-21T01:41:29.095995Z","shell.execute_reply.started":"2022-10-21T01:41:29.095627Z","shell.execute_reply":"2022-10-21T01:41:29.095763Z"},"trusted":true},"execution_count":null,"outputs":[]}]}